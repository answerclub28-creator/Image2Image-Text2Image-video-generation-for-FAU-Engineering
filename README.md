# Image2Image + Text2Image Video Generation for FAU Engineering

**Course:** CAP6415 â€“ Computer Vision (Fall 2025)  
**Team:** Akhileshwar Reddy Bommineni, Manaswini Pasupuleti, Pathri Jaydeep  
**Instructor:** Prof. Vadzim Sokol (vadzic@fau.edu)  
**University:** Florida Atlantic University â€“ College of Engineering and Computer Science  

---

## ğŸ¯ Abstract
Engineering research and education at Florida Atlantic University (FAU) benefit from realistic and creative visualizations.  
This project develops a **hybrid AI video generation pipeline** that combines **Text-to-Image (T2I)** and **Image-to-Image (I2I)** diffusion models to create short, AI-generated video clips depicting **FAU Engineering themes**â€”such as robotics, ocean engineering, autonomous drones, and smart manufacturing.

Our approach first uses a **Text-to-Image model** (Stable Diffusion / SDXL) to generate an initial frame from a descriptive prompt (e.g., â€œAn FAU robotics engineer calibrating a drone inside a modern labâ€).  
Then an **Image-to-Image refinement stage** (using ControlNet or AnimateDiff) evolves that frame into a short sequence of images showing motion or lighting change.  
Finally, the frames are stitched into a smooth video using OpenCV.  

The system is modular, reproducible, and designed for future FAU-specific dataset fine-tuning.  
All code is documented, and results can be replicated using the provided scripts.

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

git clone https://github.com/akhileshwarreddy1706/Image2Image-Text2Image-video-generation-for-FAU-Engineering.git
cd Image2Image-Text2Image-video-generation-for-FAU-Engineering

### 2ï¸âƒ£ (Recommended) Create a virtual environment

python -m venv .venv
source .venv/bin/activate     # (on macOS/Linux)
# OR
.venv\Scripts\activate        # (on Windows)

### 3ï¸âƒ£ Install dependencies

pip install -r requirements.txt

### 4ï¸âƒ£ (Optional) Create the environment via Conda

conda env create -f environment.yml
conda activate cap6415-img2vid

## Repository Structure

.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generate_frames.py        # Text-to-Image frame generation
â”‚   â”œâ”€â”€ refine_frames.py          # Image-to-Image refinement / motion
â”‚   â””â”€â”€ frames_to_video.py        # Combine frames into a video
â”‚
â”œâ”€â”€ notebooks/                    # Optional notebooks for experiments
â”œâ”€â”€ results/
â”‚   â””â”€â”€ frame_000.png             # Sample FAU Engineering frame
â”‚
â”œâ”€â”€ week1log.txt                  # Weekly progress log (Week 1 example)
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ environment.yml               # Conda environment
â”œâ”€â”€ demo_video_script.md          # Video presentation outline
â”œâ”€â”€ .gitignore                    # Ignore rules (Python + outputs)
â”œâ”€â”€ LICENSE                       # MIT License
â””â”€â”€ README.md                     # Project description